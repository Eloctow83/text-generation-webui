{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQl6-FjSYtY"
      },
      "source": [
        "# oobabooga/text-generation-webui\n",
        "\n",
        "After running both cells, a public gradio URL will appear at the bottom in around 10 minutes. You can optionally generate an API link.\n",
        "\n",
        "* Project page: https://github.com/oobabooga/text-generation-webui\n",
        "* Gradio server status: https://status.gradio.app/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [],
      "source": [
        "https://github.com/oobabooga/text-generation-webui.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (128779096.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    <audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LGQ8BiMuXMDG"
      },
      "outputs": [],
      "source": [
        "#@title 2. Launch the web UI\n",
        "\n",
        "#@markdown If unsure about the branch, write \"main\" or leave it blank.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ.pop('PYTHONPATH', None)\n",
        "\n",
        "if Path.cwd().name != 'text-generation-webui':\n",
        "  print(\"\\033[1;32;1m\\n --> Installing the web UI. This will take a while, but after the initial setup, you can download and test as many models as you like.\\033[0;37;0m\\n\")\n",
        "\n",
        "  !git clone https://github.com/oobabooga/text-generation-webui\n",
        "  %cd text-generation-webui\n",
        "\n",
        "  # Install the project in an isolated environment\n",
        "  !GPU_CHOICE=A \\\n",
        "  USE_CUDA118=FALSE \\\n",
        "  LAUNCH_AFTER_INSTALL=FALSE \\\n",
        "  INSTALL_EXTENSIONS=FALSE \\\n",
        "  ./start_linux.sh\n",
        "\n",
        "# Parameters\n",
        "model_url = \"https://huggingface.co/turboderp/gemma-2-9b-it-exl2\" #@param {type:\"string\"}\n",
        "branch = \"8.0bpw\" #@param {type:\"string\"}\n",
        "command_line_flags = \"--n-gpu-layers 128 --load-in-4bit --use_double_quant --no_flash_attn\" #@param {type:\"string\"}\n",
        "api = False #@param {type:\"boolean\"}\n",
        "\n",
        "if api:\n",
        "  for param in ['--api', '--public-api']:\n",
        "    if param not in command_line_flags:\n",
        "      command_line_flags += f\" {param}\"\n",
        "\n",
        "model_url = model_url.strip()\n",
        "if model_url != \"\":\n",
        "    if not model_url.startswith('http'):\n",
        "        model_url = 'https://huggingface.co/' + model_url\n",
        "\n",
        "    # Download the model\n",
        "    url_parts = model_url.strip('/').strip().split('/')\n",
        "    output_folder = f\"{url_parts[-2]}_{url_parts[-1]}\"\n",
        "    branch = branch.strip('\"\\' ')\n",
        "    if branch.strip() not in ['', 'main']:\n",
        "        output_folder += f\"_{branch}\"\n",
        "        !python download-model.py {model_url} --branch {branch}\n",
        "    else:\n",
        "        !python download-model.py {model_url}\n",
        "else:\n",
        "    output_folder = \"\"\n",
        "\n",
        "# Start the web UI\n",
        "cmd = f\"./start_linux.sh {command_line_flags} --share\"\n",
        "if output_folder != \"\":\n",
        "    cmd += f\" --model {output_folder}\"\n",
        "\n",
        "!$cmd"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
